{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dask.dataframe as dd\n",
    "import seaborn as sns\n",
    "from seaborn import distplot\n",
    "import seaborn as sns\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2: Data Cleaning and Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this stage, I used the raw data I retrieved in the last stage, and I cleaned and manipulate the data in order to prepare for my analysis and data modelling stages afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bts = pd.read_csv('data/bts_songs.csv')\n",
    "exo = pd.read_csv(\"data/exo_songs.csv\")\n",
    "twice = pd.read_csv(\"data/twice_songs.csv\")\n",
    "bp = pd.read_csv(\"data/blackpink_songs.csv\")\n",
    "shinee = pd.read_csv(\"data/shinee_songs.csv\")\n",
    "rv = pd.read_csv(\"data/rv_songs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I skimmed through the data, and I realized that for each artist, there are some songs that should not be used for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bts = bts.drop([78, 156, 162, 167, 218, 232, 241, 245]).reset_index().drop('index',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BTS has several skits that were retrieved but they are not really songs. Thus I removed them from the dataset. I individually found the index of these skits in the dataset and manually removed them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning data for exo songs\n",
    "# removes last non-exo albums\n",
    "exo = exo.iloc[:316]\n",
    "to_remove = []\n",
    "for label, row in exo.iterrows():\n",
    "    if 'Live Album' in exo.loc[label, 'album']:\n",
    "        to_remove.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "exo = exo.drop(to_remove).reset_index().drop('index',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While I retrieved the data of EXO songs, I realized there were many songs that did not belong to EXO, but were unintentionally retrieved. Obviously, these songs should not be included in the dataset. EXO also had \"Live Albums\", which essentially contain duplicates of previously-released songs, but with some live sounds from live concerts. Those songs were streamed much less often, which meant my dataset contained resulting in the dataset containing similar songs with drastically different popularity scores. This would affect my analysis. Thus, I also removed those kinds of albums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = []\n",
    "for label, row in shinee.iterrows():\n",
    "    if ('concert' in shinee.loc[label, 'album']) or ('CONCERT' in shinee.loc[label, 'album']):\n",
    "        to_remove.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "shinee = shinee.drop(to_remove).reset_index().drop('index',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While looking at the music data of Shinee, I realized Shinee also had a few albums from their live concerts. Thus, I also removed them from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = []\n",
    "for label, row in twice.iterrows():\n",
    "    if (twice.loc[label, 'album'] == 'Twicetagram') or ('Repackage' in twice.loc[label, 'album']):\n",
    "        to_remove.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "twice = twice.drop(to_remove).reset_index().drop('index',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While looking at Twice's dataset, I realized that there were albums that contained duplicate songs. I therefore found those albums and removed them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning data for rv songs\n",
    "rv = rv.iloc[:111]\n",
    "\n",
    "to_remove = []\n",
    "for label, row in rv.iterrows():\n",
    "    if ('Hotel Del Luna' in rv.loc[label, 'album']):\n",
    "        to_remove.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv = rv.drop(to_remove).reset_index().drop('index',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the dataset of Red Velvet, I removed this album called \"Hotel Del Luna\", because this album was part of a drama series, and Red Velvet sang the official songs of this series. This meant that the popularity score may be affected by factors other than the musical features, and the results would be inaccurate. Thus, I decided to remove this album. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning data for blackpink songs\n",
    "to_remove = []\n",
    "for label, row in bp.iterrows():\n",
    "    if ('TOUR' in bp.loc[label, 'album']) or ('BLACKPINK IN YOUR AREA' in bp.loc[label, 'album']) or ('Viral 2020' in bp.loc[label, 'album']):\n",
    "        to_remove.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp = bp.drop(to_remove).reset_index().drop('index',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blackpink also had a few albums from their live concerts, which were removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [bts, exo, twice, bp, shinee, rv]\n",
    "for i in range(len(names)):\n",
    "    # names[i] = names[i].drop(['Unnamed: 0', 'id', 'uri'], axis=1) \n",
    "    names[i] = names[i].drop_duplicates(subset='name', keep=\"first\") # removes duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing unwanted rows/songs, I removed a few unwanted columns, including: \"Unnamed: 0\" (which is a column that is automatically included after data retrieval), \"id\" (not necessary) and \"uri\" (which is the url of the song of Spotify which is also not needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bts.to_csv('bts_data_cleaned.csv')\n",
    "exo.to_csv('exo_data_cleaned.csv')\n",
    "shinee.to_csv('shinee_data_cleaned.csv')\n",
    "twice.to_csv('twice_data_cleaned.csv')\n",
    "rv.to_csv('rv_data_cleaned.csv')\n",
    "bp.to_csv('bp_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After I have cleaned the data, I saved each dataset as a new csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Stage 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this stage, I removed songs that I did not wish to include in my dataset. \n",
    "- These songs included: songs from repackaged albums (duplicatess), songs that were unintentionally scraped (errors), and songs that were potentially confounded by other variables (theme songs from drama series), and songs from live concerts. \n",
    "- I also removed a few columns that were not necessary.\n",
    "- Overall, this stage was important for preparing the dataset appropriately for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
